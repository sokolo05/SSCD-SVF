training:
  epochs: 30
  batch_size: 64
  learning_rate: 1e-4
  weight_decay: 1e-2
  gradient_clip: 1.0
  early_stopping:
    patience: 5
    min_delta: 1e-4

optimizer:
  type: AdamW
  betas: [0.9, 0.999]
  eps: 1e-8

scheduler:
  type: CosineAnnealingLR
  T_max: 30
  eta_min: 1e-6

data:
  image_size: [224, 224]
  normalize_mean: [0.485, 0.456, 0.406]
  normalize_std: [0.229, 0.224, 0.225]
  num_workers: 4
  pin_memory: true
